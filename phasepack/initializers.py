"""
This module provides the collection of initialization algritithms proposed in
phasepack.

Funcions
--------

init_spectral       This

Based on MATLAB implementation by Rohan Chandra, Ziyuan Zhong, Justin Hontz,
Val McCulloch, Christoph Studer & Tom Goldstein.
Copyright (c) University of Maryland, 2017.
Python version of the phasepack module by Juan M. Bujjamer.
University of Buenos Aires, 2018.
"""

__version__ = "1.0.0"
__author__ = 'Juan M. Bujjamer'
__all__ = ['init_spectral', 'init_optimal_spectral']

import numpy as np
from numpy.linalg import norm
from scipy.sparse.linalg import eigs

from phasepack.containers import Options
from phasepack.matops import ConvolutionMatrix


def  init_spectral(A, b0, At=None, is_scaled=False, is_truncated=False, verbose=False):
    """ Intializer proposed in Algorithm 1 of the Wirtinger Flow paper.

    This initializer forms a matrix from the data and computes the largest
    eigenvector that is shown to be positively correlated with the unknown true
    signal. This script presents both the vanilla spectral method and the
    truncated spectral method. A recently proposed 'optimal' spectral
    initializer method was proposed and is presented in a different function.

    Parameters:
    -------
    A:  ndarray or ConvolutionMatrix.
        This is the (n x m) matrix or the ConvolutionMatrix used to perform all the
        operations for the reconstruction. Prefer ConvolutionMatrix for optimization.
    At: ndarray
        Deprecated. If a ConvolutionMatrix is used, it contains this information.
    b0: array
        m x 1 real, non-negative vector consists of all the measurements.
    n:  int
        The size of the unknown signal. Deprecated, if a ConvolutionMatrix is used, it
        contains this information.
    is_truncated: bool
        If true, use the 'truncated' initializer that uses a sub-sample of the
        measurement.
    is_scale: bool
        If true, use a least-squares method to determine  the optimal scale of
        the initializer.

    Note:
    -----
    Always use an instance of the ConvolutionMatrix class prefereably.

    Returns:
    --------
    x0: array
        A n x 1 vector. It is the guess generated by the spectral method for
        the unknown signal.

    See the script 'test_init_spectral.py' for an example of proper usage of this
    function.

    Notations:
    ----------
    Our notations follow the TWF paper.
    ai is the conjugate transpose of the ith row of A.
    yi is the ith element of y, which is the element-wise square of the
    measurements b0.

    Algorithm Description:
    ----------------------
    The method has two steps
    (1) If is_truncated==True, Discard those observations yi that are
        several times greater than the mean during spectral initialization.
    (2) Calculate the leading eigenvector of a matrix Y,
        where Y = 1/m sum(yi * ai * ai') for i = 1 to m.
    The method return this leading eigenvector, which is calcualted using
    the routine specified in conv_matrix (default is scipy.sparse.eigs()).

    Note: The truncation, when used, makes the method more robust to outlier
    and performs better in practice.

    For a detailed explanation, see Algorithm 1 in the TWF paper referenced
    below.

    References:
    -----------
    For spectral method
    Paper Title:   Phase Retrieval via Wirtinger Flow: Theory and Algorithms
    Place:         Algorithm 1
    Authors:       Emmanuel Candes, Xiaodong Li, Mahdi Soltanolkotabi
    Arxiv Address: https://arxiv.org/abs/1407.1065

    For truncated spectral method
    Paper Title:   Solving Random Quadratic Systems of Equations Is Nearly as
                   Easy as Solving Linear Systems
    Place:         Algorithm 1
    Authors:       Yuxin Chen, Emmanuel J. Candes
    Arxiv Address: https://arxiv.org/abs/1505.05114
    """

    m = b0.size  # number of measurements
    if verbose:
        print('Estimating signal of length %d using a spectral initializer with %d measurements...' % (A.n, m))

    # Truncated Wirtinger flow initialization
    alphay = 3                      # (4 also works fine)
    y = b0**2                       # To be consistent with the notation in the TWF paper Algorithm 1.
    lambda0 = np.sqrt(1/m*sum(y))   # Defined in the TWF paper Algorithm 1
    idx = np.ones((b0.size, 1))         # Indices of observations yi
    # Truncate indices if is_truncated is true
    # It discards those observations yi that are several times greater than
    # the mean during spectral initialization.
    if is_truncated:
        idx = np.abs(y)<=alphay**2*lambda0**2

    # Build the function handle associated to the matrix Y
    # in the TWF paper Algorithm 1
    [eval, x0] = A.calc_yeigs(m, b0, idx)
    # This part does not appear in the paper. We add it for better
    # performance. Rescale the solution to have approximately the correct
    # magnitude
    if is_scaled:
        # Pick measurements according to the indices selected
        b = b0*idx
        Ax = np.abs(A*x0)*idx
        # solve min_s || s|Ax| - b ||
        u = Ax*b
        l = Ax*Ax
        s = norm(u)/norm(l)
        x0 = x0*s  # Rescale the estimation of x

    if verbose:
        print('Initialization finished.')

    return x0

def init_optimal_spectral(A, b0, At=None, is_scaled=False, is_truncated=False, verbose=False):
    """
    Optimal spectral initializer.

    Initializer recently proposed based on an optimal spectral method. The
    plain vanilla spectral initializer computes the largest eigenvector of Y
    = 1/m sum(yi * ai * ai') for i = 1 to m.  The truncated version of this
    method throws away some of the rows.  The optimal spectral nitializer
    computes the largest eigenvector of Y = 1/m sum(T(yi) * ai * ai') for i
    = 1 to m, where T(yi) is a function of yi given in equation (5) of the
    paper cited below.

    Parameters:
    -----------
       A:  m x n matrix (or optionally a function handle to a method) that
           returns A*x.
       At: The adjoint (transpose) of 'A'. If 'A' is a function handle, 'At'
           must be provided.
       b0: m x 1 real,non-negative vector consists of all the measurements.
       n:  The size of the unknown signal. It must be provided if A is a
           function handle.
       is_truncated (boolean): If true, use the 'truncated' initializer that
                              uses a sub-sample of the measurement.
       is_scaled (boolean):    If true, use a least-squares method to
                              determine  the optimal scale of the
                              initializer.

       Note: When a function handle is used, the value of 'n' (the length of
       the unknown signal) and 'At' (a function handle for the adjoint of
       'A') must be supplied.  When 'A' is numeric, the values of 'At' and
       'n' are ignored and inferred from the arguments.

    Outputs:
    --------
       x0:  A n x 1 vector. It is the guess generated by the spectral method
            for  the unknown signal.

    See the script 'test_init_optimal_spectral.m' for an example of proper usage of
    this function.

     Notation
    Our notation follows the TWF paper.
    ai is the conjugate transpose of the ith row of A.
    yi is the ith element of y, which is the element-wise square of the
    measurements b0.

     Algorithm Description.
    Calculate the leading eigenvector of a matrix Y, where Y = 1/m sum(T(yi)
    * ai * ai') for i = 1 to m, where T() is a "pre-processing" function.
    The method return this leading eigenvector,
    which is calculated using Matlab's eigs() routine.

    Note: This implementation differs from the paper in several ways that
    make it more efficient and robust.
    The papers below recommend using the power method to compute the leading
    eigenvector.  Our implemention
    uses Matlab's built-in function eigs() to get the leading eigenvector
    because of greater efficiency.

    Also, the authors define the pre-processing function
                   T(z) = (z-1)/(z+sqrt(delta)-1),
    where delta is the ratio of number of measurements to number of
    dimensions.  This formula assumes that the measurements are Gaussian with
    variance 1/n, and the unknown signal has length sqrt(n).  This assumption
    is clearly violated by most real sensing matrices and signals.  However,
    note that this measurements model yields measurements y = abs(Ax)^2 that
    have expected value E(y)=1.  For this reason, we normalize the
    measurements to have mean 1 before we apply the pre-processing function.
    We then multiply the mean back into the results when we're done
    pre-processing.

    % References
     Title:   Fundamental Limits of Weak Recovery with Applications to Phase
              Retrieval
     Place:   Equations (4) and (5)
     Authors: Marco Mondelli, Andrea Montanari
     Arxiv Address: https://arxiv.org/pdf/1708.05932.pdf

    PhasePack by Rohan Chandra, Ziyuan Zhong, Justin Hontz, Val McCulloch,
    Christoph Studer, & Tom Goldstein
    Copyright (c) University of Maryland, 2017
    """
    m = b0.size  # number of measurements

    if verbose:
        print('Estimating signal of length %d using the optimal spectral initializer with %d measurements...' % (A.n, m))

    # Measurements as defined in the paper
    y = b0**2
    delta = m/A.n    # Used in equation (5) of paper

    # Normalize the measurements
    ymean = np.mean(y)
    y = y/ymean

    # Apply pre-processing function
    yplus = np.maximum(y, 0) # Element-wise max
    T = (yplus-1)/(yplus+np.sqrt(delta)-1)  # Formula from equation 25 in paper

    # Un-normalize the measurements
    T *= ymean

    idx = np.ones((b0.size, 1)) # Indices of observations yi
    # Our implemention uses Matlab's built-in function eigs() to get the leading
    # eigenvector because of greater efficiency.
    # Create opts struct for eigs
    # Yfunc = @(x) 1/m*At(T.*A(x));
    x0 = A.calc_yeigs(m, T, idx)
    if is_scaled:
        # Pick measurements according to the indices selected
        b = b0
        Ax = np.abs(A*x0)
        # solve min_s || s|Ax| - b ||
        u = Ax*b
        l = Ax*Ax
        s = norm(u)/norm(l)
        x0 = x0*s  # Rescale the estimation of x
    if verbose:
        print('Initialization finished.')

    return x0
